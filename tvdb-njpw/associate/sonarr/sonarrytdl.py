from .logging import logger
from .models import (
    Association,
    Configuration,
    NjpwWorldEpisode,
    SeriesConfiguration,
    TvdbEpisode,
)
from datetime import datetime, timedelta
import os
import re
import requests
import urllib
import yt_dlp


date_format = "%Y-%m-%dT%H:%M:%SZ"


class SonarrClient:
    def __init__(self) -> None:
        config = Configuration.objects.all()
        self.base_url = config.filter(key="sonarr_base_url").get().value
        self.sonarr_api_version = config.filter(key="sonarr_api_version").get().value
        self.api_key = config.filter(key="sonarr_api_key").get().value
        self.series = SeriesConfiguration.objects.all().iterator()
        self.debug = bool(config.filter(key="ytdl_debug").get().value)

    def request_get(self, url, params=None):
        """Wrapper on the requests.get"""
        logger.debug(f"Begin GET with url: {url}")
        args = {"apikey": self.api_key}
        if params is not None:
            logger.debug(f"Begin GET with params: {params}")
            args.update(params)
        url = f"{url}?{urllib.parse.urlencode(args)}"
        res = requests.get(url)
        return res

    def request_put(self, url, params=None, jsondata=None):
        logger.debug(f"Begin PUT with url: {url}")
        """Wrapper on the requests.put"""
        headers = {
            "Content-Type": "application/json",
        }
        args = (("apikey", self.api_key),)
        if params is not None:
            args.update(params)
            logger.debug(f"Begin PUT with params: {params}")
        res = requests.post(url, headers=headers, params=args, json=jsondata)
        return res

    def get_series(self):
        """Return all series in your collection"""
        logger.debug("Begin call Sonarr for all available series")
        res = self.request_get(f"{self.base_url}/{self.sonarr_api_version}/series")
        return res.json()

    def get_series_by_series_id(self, series_id):
        """Return the series with the matching ID or 404 if no matching series is found"""
        logger.debug(f"Begin call Sonarr for specific series series_id: {series_id}")
        res = self.request_get(
            f"{self.base_url}/{self.sonarr_api_version}/series/{series_id}"
        )
        return res.json()

    def get_episodes_by_series_id(self, series_id):
        """Returns all episodes for the given series"""
        logger.debug(f"Begin call Sonarr for all episodes for series_id: {series_id}")
        args = {"seriesId": series_id}
        res = self.request_get(
            f"{self.base_url}/{self.sonarr_api_version}/episode", args
        )
        return res.json()

    def get_episode_files_by_series_id(self, series_id):
        """Returns all episode files for the given series"""
        args = {"seriesId": series_id}
        res = self.request_get(
            f"{self.base_url}/{self.sonarr_api_version}/episodefile",
            args,
        )
        return res.json()

    def rescanseries(self, series_id):
        """Refresh series information from trakt and rescan disk"""
        logger.debug(f"Begin call Sonarr to rescan for series_id: {series_id}")
        data = {"name": "RescanSeries", "seriesId": str(series_id)}
        res = self.request_put(
            f"{self.base_url}/{self.sonarr_api_version}/command", None, data
        )
        return res.json()

    def filterseries(self):
        """Return all series in Sonarr that are to be downloaded by youtube-dl"""
        series = self.get_series()
        matched = []
        # rewrite all this because most of it doesn't matter for njpw
        for ser in series[:]:
            for wnt in self.series:
                if wnt.title == ser["title"]:
                    # Set default values
                    ser["subtitles"] = False
                    ser["playlistreverse"] = True
                    ser["subtitles_languages"] = ["en"]
                    ser["subtitles_autogenerated"] = False
                    if "offset" in wnt.settings:
                        ser["offset"] = wnt.settings["offset"]
                    if wnt.cookie is not None:
                        ser["cookie"] = wnt.cookie
                    matched.append(ser)
        for check in matched:
            if not check["monitored"]:
                logger.warn(f"{ser['title']} is not currently monitored")
        del series[:]
        return matched

    def getseriesepisodes(self, series):
        needed = []
        now = datetime.now()
        for ser in series[:]:
            episodes = self.get_episodes_by_series_id(ser["id"])
            for eps in episodes[:]:
                eps_date = now
                if "airDateUtc" in eps:
                    eps_date = datetime.strptime(eps["airDateUtc"], date_format)
                    if "offset" in ser:
                        eps_date = offsethandler(eps_date, ser["offset"])
                if not eps["monitored"] or eps["hasFile"] or eps_date > now:
                    logger.debug(
                        "not downloading [{0}]; monitored [{1}]; has file [{2}]; [{3}] > [{4}]".format(
                            eps["title"],
                            eps["monitored"],
                            eps["hasFile"],
                            eps_date,
                            now,
                        )
                    )
                    episodes.remove(eps)
                else:
                    if "sonarr_regex_match" in ser:
                        match = ser["sonarr_regex_match"]
                        replace = ser["sonarr_regex_replace"]
                        eps["title"] = re.sub(match, replace, eps["title"])
                    needed.append(eps)
                    continue
            if len(episodes) == 0:
                logger.info(f"{ser['title']} no episodes needed")
                series.remove(ser)
            else:
                logger.info(f"{ser['title']} missing {len(episodes)} episodes")
                for i, e in enumerate(episodes):
                    logger.info(f"  {i + 1}: {ser['title']} - {e['title']}")
        return needed

    def njpw_search(self, series_id, tvdb_id):
        try:
            episode = (
                Association.objects.filter(
                    njpw_world_episode__series__id=series_id, tvdb_episode__id=tvdb_id
                )
                .get()
                .njpw_world_episode
            )
            return True, episode
        except:
            return False, None

    def download(self, series, episodes):
        if len(series) != 0:
            logger.info("processing episodes to download")
            for s, ser in enumerate(series):
                logger.debug(f"  [{ser['title']}]")
                for e, ep in enumerate(episodes):
                    if ser["id"] == ep["seriesId"]:
                        cookies = None
                        if "cookie" in ser:
                            cookie = ser["cookie"]
                            cookies = cookie.write_temp_file()
                        logger.debug(
                            f"searching for episode [{ep['title']}:{ep['tvdbId']}] and series id [{ep['seriesId']}]"
                        )
                        found, njpw_ep = self.njpw_search(ser["id"], ep["tvdbId"])
                        if found:
                            dlurl = njpw_ep.url
                            outtmpl = "/sonarr_root{0}/Season {1}/{2} - S{1}E{3} - {4} WEBDL.%(ext)s".format(
                                ser["path"],
                                ep["seasonNumber"],
                                ser["title"],
                                ep["episodeNumber"],
                                ep["title"],
                            )
                            logger.info(
                                f"downloading [{ep['title']}] from [{dlurl}] to [{outtmpl}]"
                            )
                            ytdl_format_options = {
                                "quiet": True,
                                "merge-output-format": "mp4",
                                "outtmpl": outtmpl,
                                "progress_hooks": [ytdl_hooks],
                                "noplaylist": True,
                            }
                            ytdl_format_options = appendcookie(
                                ytdl_format_options, cookies
                            )
                            try:
                                yt_dlp.YoutubeDL(ytdl_format_options).download([dlurl])
                                njpw_ep.downloaded_at = datetime.now()
                                njpw_ep.save()
                                self.rescanseries(ser["id"])
                                logger.info(f"      Downloaded - [{ep['title']}]")
                            except Exception as e:
                                logger.error(f"      Failed - [{ep['title']}] - [{e}]")
                            finally:
                                cookie.remove_temp_file()
                        else:
                            logger.debug(f"    [{e + 1}]: Missing - [{ep['title']}]:")
        else:
            logger.info("nothing to process")


def ytdl_hooks(d):
    if d["status"] == "finished":
        file_tuple = os.path.split(os.path.abspath(d["filename"]))
        logger.info(f"      Downloaded - [{file_tuple[1]}]")


def appendcookie(ytdlopts, cookies=None):
    """Checks if specified cookie file exists in config
    - ``ytdlopts``: Youtube-dl options to append cookie to
    - ``cookies``: filename of cookie file to append to Youtube-dl opts
    returns:
        ytdlopts
            original if problem with cookies file
            updated with cookies value if cookies file exists
    """
    if cookies is not None:
        cookie_exists = os.path.exists(cookies)
        if cookie_exists is True:
            ytdlopts.update({"cookiefile": cookies})
            # if self.debug is True:
            logger.debug(f"  Cookies file used: {cookies}")
        if cookie_exists is False:
            logger.warning("  cookie files specified but doesn't exist.")
        return ytdlopts
    else:
        return ytdlopts


def offsethandler(airdate, offset):
    """Adjusts an episodes airdate
    - ``airdate``: Airdate from sonarr # (datetime)
    - ``offset``: Offset from series config # (dict)
    returns:
        ``airdate``: datetime updated original airdate
    """
    weeks = 0
    days = 0
    hours = 0
    minutes = 0
    if "weeks" in offset:
        weeks = int(offset["weeks"])
    if "days" in offset:
        days = int(offset["days"])
    if "hours" in offset:
        hours = int(offset["hours"])
    if "minutes" in offset:
        minutes = int(offset["minutes"])
    airdate = airdate + timedelta(weeks=weeks, days=days, hours=hours, minutes=minutes)
    return airdate


def download_pending():
    client = SonarrClient()
    series = client.filterseries()
    episodes = client.getseriesepisodes(series)
    client.download(series, episodes)
    logger.info("waiting...")


def get_recent_downloads(limit: int = 5) -> list[TvdbEpisode]:
    downloads = NjpwWorldEpisode.objects.order_by("-downloaded_at")[:limit].values_list(
        "id", flat=True
    )
    associations = Association.objects.filter(njpw_world_episode__id__in=downloads)
    episodes = map(lambda a: a.tvdb_episode.id, list(associations))
    recent_downloads = list(TvdbEpisode.objects.filter(id__in=episodes))
    logger.debug(f"recent downloads [{recent_downloads}]")
    return recent_downloads
